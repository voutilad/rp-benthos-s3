# Global settings.
logger:
  level: INFO
  format: json
http:
  enabled: false

input:
  label: get_next_event
  http_client:
    url: "http://${AWS_LAMBDA_RUNTIME_API}/2018-06-01/runtime/invocation/next"
    timeout: "5s"
    auto_replay_nacks: false
    extract_headers:
      include_patterns: [ "lambda-runtime-aws-*" ]

cache_resources:
  - label: key_cache
    memory: {}

pipeline:
  processors:
    # Deduplicate any repeat events since we keep polling the API.
    - dedupe:
        cache: key_cache
        key: ${! metadata("lambda-runtime-aws-request-id") }
    # We got an event!
    - log:
        message: processing request ${! metadata("lambda-runtime-aws-request-id")  }
    # Main S3 event processing logic
    - label: parse_event
      processors:
        # Extract our Records Array.
        - jq:
            query: ".Records"
        # Iterate over the events as we may have multiple.
        # (In practice, not sure if this happens.)
        - unarchive:
            format: json_array
        # Extract the useful identifiers for the S3 object(s), drop content.
        - mapping: |
            meta region = this.awsRegion
            meta key = this.s3.object.key
            meta bucket = this.s3.bucket.name
            meta outcome = "error"
            root = ""
    # Fetch a copy of our Redpanda Cloud connection details and extract them.
    - branch:
        request_map: |
          root = "" # All info is in the query string.
        processors:
          - http:
              url: "http://localhost:${PARAMETERS_SECRETS_EXTENSION_HTTP_PORT:2773}/secretsmanager/get?secretId=${RP_CONNECT_SECRETS_ID}"
              verb: GET
              retries: 3
              backoff_on: [ 400 ]
              drop_on: [ 403, 500 ]
              max_retry_backoff: "30s"
              headers:
                X-Aws-Parameters-Secrets-Token: "${AWS_SESSION_TOKEN}"
          # Parse and extract embedded JSON from the response.
          - mapping: |
              root = content().string().parse_json().SecretString.parse_json()
        result_map: |
          meta broker = this.RP_CONNECT_BROKER
          meta username = this.RP_CONNECT_USERNAME
          meta password = this.RP_CONNECT_PASSWORD
          meta sasl_mech = this.RP_CONNECT_SASL_MECH
          meta use_tls = this.RP_CONNECT_TLS
    # Fire off a secondary Redpanda Connect instance.
    - log:
        message: 'processing s3://${! metadata("bucket") }/${! metadata("key") } in ${! metadata("region") }'
    - command:
        name: rpk
        args_mapping: |
          [
            "connect", "run",
            "--set", "input.aws_s3.bucket=%s".format(metadata("bucket")),
            "--set", "input.aws_s3.region=%s".format(metadata("region")),
            "--set", "input.aws_s3.prefix=%s".format(metadata("key")),
            "--set", "output.kafka_franz.seed_brokers.0=%s".format(metadata("broker")),
            "--set", "output.kafka_franz.sasl.0.mechanism=%s".format(metadata("sasl_mech")),
            "--set", "output.kafka_franz.sasl.0.username=%s".format(metadata("username")),
            "--set", "output.kafka_franz.sasl.0.password=%s".format(metadata("password")),
            "--set", "output.kafka_franz.tls.enabled=%s".format(metadata("use_tls").or("false").string()),
            "config.yaml"
          ]
    # Construct a Lambda function response per:
    # https://docs.aws.amazon.com/apigateway/latest/developerguide/http-api-develop-integrations-lambda.html
    - switch:
        # Failure :(
        - check: errored()
          processors:
            - log:
                message: error in subprocessor
                fields_mapping: |
                  root.stderr = metadata("command_stderr").or("")
                  root.stdout = content().string()
            - mapping: |
                meta outcome = "error"
                root.errorMessage = "failed to process s3://%s/%s".format(
                  metadata("bucket"), metadata("key")
                )
                root.errorType = "UnknownError"
                root.stackTrace = metadata("command_stderr").or("").split("\n")
        # Success :) Try to parse the log output so we can relay it.
        - processors:
            - log:
                message: subprocess was successful
            - mapping: |
                meta outcome = "response"
                root.id = metadata("lambda-runtime-aws-request-id")
                root.message = "processed s3://%s/%s".format(
                  metadata("bucket"), metadata("key")
                )

output:
  label: lambda_response
  http_client:
    url: http://${AWS_LAMBDA_RUNTIME_API}/2018-06-01/runtime/invocation/${! metadata("lambda-runtime-aws-request-id") }/${! metadata("outcome") }
    verb: POST
    max_in_flight: 1

# Tests for our data transformation logic.
# See https://docs.aws.amazon.com/lambda/latest/dg/with-s3-example.html
tests:
  - name: Test parsing S3 event
    target_processors: parse_event
    input_batch:
      - content: |
          {
            "Records": [{
              "eventVersion": "2.0",
              "eventSource": "aws:s3",
              "awsRegion": "us-east-1",
              "eventTime": "1970-01-01T00:00:00.000Z",
              "eventName": "ObjectCreated:Put",
              "userIdentity": {
                "principalId": "EXAMPLE"
              },
              "requestParameters": {
                "sourceIPAddress": "127.0.0.1"
              },
              "responseElements": {
                "x-amz-request-id": "EXAMPLE123456789"
              },
              "s3": {
                "s3SchemaVersion": "1.0",
                "configurationId": "testConfigRule",
                "bucket": {
                  "name": "DOC-EXAMPLE-BUCKET",
                  "ownerIdentity": {
                    "principalId": "EXAMPLE"
                  },
                  "arn": "arn:aws:s3:::DOC-EXAMPLE-BUCKET"
                },
                "object": {
                  "key": "testkey",
                  "size": 1024,
                  "eTag": "0123456789abcdef0123456789abcdef",
                  "sequencer": "0A1B2C3D4E5F678901"
                }
              }
            }]
          }
    output_batches:
      - # We should have all our object details in metadata and no message body.
        - metadata_equals:
            region: us-east-1
            key: testkey
            bucket: DOC-EXAMPLE-BUCKET
          content_equals: ""
