input:
  file:
    paths: [ "${RP_CONNECT_INPUT:./samples/*.tar.gz}" ]
    scanner:
      decompress:
        algorithm: "gzip"
        into:
          tar: {}

buffer:
  none: {}

pipeline:
  processors:
    # Drop some metadata that comes from our tarball.
    - mapping: |
        if !content().has_prefix("{") { deleted() }
    # Split out the newline-delimitted JSON into individual messages.
    - unarchive:
        format: "json_documents"
    # Play with it for now.
    - mapping: |
        root.text = this.abstract
        root.metadata.title = this.name
        root.metadata.url = this.url
        root.metadata.identifier = this.identifier
        root.metadata.event = this.event

output:
  kafka_franz:
    seed_brokers: [ "${RP_CONNECT_BROKER:127.0.0.1:9092}" ]
    topic: "${RP_CONNECT_TOPIC:wikipedia}"
    tls:
      enabled: ${RP_CONNECT_TLS:false}
    sasl:
      - mechanism: "${RP_CONNECT_SASL_MECH:none}"
        username: "${RP_CONNECT_USERNAME:}"
        password: "${RP_CONNECT_PASSWORD:}"
    batching:
      byte_size: 1048576
      period: "5s"
